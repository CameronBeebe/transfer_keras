{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of TL_keras_lab-FIX.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/CameronBeebe/transfer_keras/blob/TL-FIX/Copy_of_TL_keras_lab_FIX.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "smiajbdRUt8Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential, load_model, Model, Input\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPool2D, InputLayer, ZeroPadding2D, GlobalAvgPool2D, Reshape, Softmax\n",
        "from keras.datasets import cifar10\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize\n",
        "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7dYwkLgHUt8U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  This tutorial attempts to achieve transfer learning on incompatible image sizes with MobileNet.\n",
        "#  Why do this, when we could just load a different (compatible) data set, or use a different model?\n",
        "#  Because!  Well, this is a tutorial, and it illustrates some practical issues implementing transfer learning.\n",
        "#  We will resize a small batch of images to show how pre-trained weights affect fitting and prediction.\n",
        "#  The unbiased and biased MobileNet objects will have the same layer architecture except for the weights.\n",
        "#  For such a small dataset, the results using a pre-trained network are much better than when starting with a fresh network.\n",
        "#  However, both models in the current set-up have performed terribly on prediction and validation.\n",
        "#  With such small data sets, \n",
        "\n",
        "\n",
        "#  This notebook is intended to be used with a GPU.  \n",
        "#  Otherwise, it just takes too long to train and experiment.\n",
        "#  I recommend doing it on Google Colab:  https://colab.research.google.com/\n",
        "\n",
        "#  Table of Contents:\n",
        "#  \n",
        "#  1.  Data Processing\n",
        "#  2.  Create MobileNet Conv. Net. Models\n",
        "#  3.  Prediction and Scoring\n",
        "#\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QkbUzmUZUt8W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 1.  Data Processing"
      ]
    },
    {
      "metadata": {
        "id": "UUpGeis3Ut8X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Data: (32,32,3) Images"
      ]
    },
    {
      "metadata": {
        "id": "48vpwiEdUt8X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#  Check shapes."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-wiKTns-Ut8b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  Convince yourself that the labels are consistent with the data.  \n",
        "#  See https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "print(y_train[4999])   \n",
        "plt.imshow(x_train[4999])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g6di6FYLUt8d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Resize Train Data"
      ]
    },
    {
      "metadata": {
        "id": "Xj7B7syVUt8d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "#  Pretrained weights only exist for certain shapes, which is why we get an error with smaller image sizes.\n",
        "#  One option to deal with the fact that MobileNet does not like (32,32,3) shape is to resize the images.\n",
        "#  NOTE:  Resizing the entire training data set would take, with my precise calculations, a very long time.\n",
        "#  I will only be resizing and training on 5,000.  If you want to save afterwards, it will create about a 2 gig file.  \n",
        "#  I will not include a resized file on github (although it is possible to host large files).\n",
        "#  \n",
        "#  It is much faster for me when on Google Colab (~12 minutes).  \n",
        "#  If you want to load a saved file, you might have to host it on Google Drive.\n",
        "#  You might get a memory warning (which is also one reason it takes so long on my computer).\n",
        "\n",
        "#  I tried 10000 on Colab.  It took about 45 minutes filling up 12 Gigs of memory.  Runtime crash ensues.\n",
        "#  8000 ~30min, crash\n",
        "#  7000 ~20 min, did okay for a few trains and then crash\n",
        "#  6000 may be stable\n",
        "\n",
        "#  Base case.\n",
        "resized_train_data = []\n",
        "resized_train_data = np.reshape(np.append(resized_train_data, resize(x_train[0],(128,128,3))),(128,128,3))\n",
        "\n",
        "#  Change range to 50000 if you want to do the entire set.  NOT RECOMMENDED\n",
        "for row in range(5000):\n",
        "    if row > 0:\n",
        "        resized = resize(x_train[row],(128,128,3))\n",
        "        resized_train_data = np.reshape(np.append(resized_train_data, resized),((row+1),128,128,3))\n",
        "          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1il0RoR7tgRg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  Check\n",
        "plt.imshow(resized_train_data[4999])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Lorb1WBUt8j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Resize Test Data"
      ]
    },
    {
      "metadata": {
        "id": "h24aAvqgUt8j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  Also resize test data\n",
        "resized_test_data = []\n",
        "resized_test_data = np.reshape(np.append(resized_test_data, resize(x_test[0],(128,128,3))),(128,128,3))\n",
        "\n",
        "#  Change range to 10000 if you want to resize entire test data.  NR\n",
        "for row in range(1000):\n",
        "    if row > 0:\n",
        "        resized = resize(x_test[row],(128,128,3))\n",
        "        resized_test_data = np.reshape(np.append(resized_test_data, resized),((row+1),128,128,3))\n",
        "          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cj-LK-tNUt8m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(x_test[17])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BEznDY_AUt8t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(resized_test_data[17])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EbaIQAJvUt83",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Scale Data"
      ]
    },
    {
      "metadata": {
        "id": "6erNDI0kUt83",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "resized_train_data /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zGDi3VUZUt86",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  Also for test data (which may have a different name if you are loading them.)\n",
        "resized_test_data /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tvnd0WTxbtyu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "resized_train_data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qKIXRvlKUt89",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Encode Category Labels"
      ]
    },
    {
      "metadata": {
        "id": "bySriqGeUt8-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  Encode labels.\n",
        "y_train_encoded = np_utils.to_categorical(y_train)\n",
        "y_test_encoded = np_utils.to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I1xGjxmqUt9A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  Grab relevant number of labels for resized batch.\n",
        "fivek_labels = y_test_encoded[:5000]\n",
        "fivek_labels.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p5iUog-YUt9C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2.  Create MobileNet Conv. Net. Models"
      ]
    },
    {
      "metadata": {
        "id": "tox14jD8Ut9D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create Unbiased Conv. NN"
      ]
    },
    {
      "metadata": {
        "id": "N6JXlAXZUt9F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  With the resized image shapes, we can use them directlly with MobileNet.  \n",
        "#  Otherwise, it would throw an error that the input_shape is too small.\n",
        "#  However, I am using a dataset of 5000, which does not seem to train very well.\n",
        "#  It will do pretty good in higher numbers of epochs, which you can check.\n",
        "#  This illustrates one of the uses of transfer learning:  when data sets are too small to properly train.\n",
        "\n",
        "fresh = MobileNet(input_shape=(128,128,3),include_top =True, weights=None,classes=10)\n",
        "fresh.summary()\n",
        "fresh.compile(optimizer='adadelta',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ky4D34z3Ut9I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fit"
      ]
    },
    {
      "metadata": {
        "id": "DRMKUQbTUt9J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "#  Note how long it takes to train per epoch, the loss, and accuracy.  \n",
        "#  We will compare with the pre-trained model below.\n",
        "history_fresh = fresh.fit(resized_train_data,fivek_labels,epochs = 20,batch_size=64,validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G3ASvFFyUt9O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Plot"
      ]
    },
    {
      "metadata": {
        "id": "Q7s1tXm6Ut9P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history_fresh.history['loss'])\n",
        "#plt.plot(history_fresh.history['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o21hJE4UUt9R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create Biased Conv. NN"
      ]
    },
    {
      "metadata": {
        "id": "KBDOqZYFUt9R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  Since we are doing a more complex model, we use the functional API Model() class from keras. \n",
        "#  This lets us be very explicit about inputs and outputs for the layers in the model.\n",
        "    \n",
        "#  Create tensor object to pass into the trained_model.\n",
        "inputs = Input(shape = (128,128,3)) \n",
        "\n",
        "#  For this MobileNet object with pre-trained weights, we will need to chop off the classification layers: include_top=False. \n",
        "trained_model = MobileNet(input_shape = (128,128,3),include_top = False, weights='imagenet', input_tensor = inputs)\n",
        "\n",
        "#  Freeze: keep some pre-trained weights as they are.  Somebody already spent time training to classify images.\n",
        "#  I am freezing everything except the last depthwise convolution (and classification convolution).\n",
        "#  Check number of trainable parameters in summary after freezing layers.\n",
        "#  Compare results when training all pre-trained weights and when freezing some (or all) weights.  \n",
        "#  Why does convergence suffer when all weights are frozen?\n",
        "for layer in trained_model.layers[:89]:\n",
        "    layer.trainable = False\n",
        "\n",
        "#  Then, copy as close as possible the structure of the layers removed by include_top=False.\n",
        "x = GlobalAvgPool2D(data_format='channels_last')(trained_model.output)\n",
        "x = Reshape((1,1,-1))(x)\n",
        "\n",
        "#  Adjust dropout rate (e.g. try 0.5) to see how it helps prevent overfitting.  \n",
        "#  Alternatively, you can just use less epochs.\n",
        "x = Dropout(rate=0.001)(x)\n",
        "x = Conv2D(filters=10,kernel_size=(1,1))(x)\n",
        "x = Activation(activation = 'softmax')(x)\n",
        "predictions = Reshape((-1,))(x)\n",
        "\n",
        "#  Put the layers together by a transfer_model that takes inputs and outputs.\n",
        "transfer_model = Model(inputs = inputs,outputs = predictions)\n",
        "transfer_model.compile(optimizer = 'adadelta',loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
        "transfer_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cZhoJfM8Ut9U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "#  Notice fitting the pre-trained model is much quicker, each epoch takes much less time.\n",
        "#  Additionally, the rate of accuracy increase and loss decrease is much higher.\n",
        "#  It can even be considered 'overfitting' in a fraction of the time the unbiased network takes to fit.\n",
        "#  Try adjusting the dropout rate to mitigate overfitting, or reducing epochs.\n",
        "history_transfer = transfer_model.fit(resized_train_data,fivek_labels,epochs=20,batch_size=64,validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XJgTyAcUUt9X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Compare Performance"
      ]
    },
    {
      "metadata": {
        "id": "LgF5oJSaUt9X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history_transfer.history['loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D3PRTjDlUt9a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history_transfer.history['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SgVbcFEFUt9c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  Compare with plots from unbiased network.\n",
        "plt.plot(history_fresh.history['loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "weNzvEIlUt9e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history_fresh.history['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JocWKtJOUt9g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3.  Prediction and Scoring"
      ]
    },
    {
      "metadata": {
        "id": "Zmko9STQUt9h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  NOTE:  In the current state, these models are not good at prediction.\n",
        "#  We could see this by looking at the validation accuracy when training above.\n",
        "#  Try experimenting to improve validation when training.\n",
        "\n",
        "#  See how our transferred model does on the test data set.\n",
        "#  We hope to get comparible prediction scores.\n",
        "\n",
        "#  Supress scientific notation for easier comparison.\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "#  Predict a class and look at an example to compare between biased and unbiased.\n",
        "#  What do you expect the comparison to show?\n",
        "unbiased_prediction = fresh.predict(resized_test_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4f05twLwUt9k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unbiased_prediction[158]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IUE7sQK-Ut9m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  Note: predict gives us probabilities like predict_proba for other models.  Check that they sum to one.\n",
        "sum(unbiased_prediction[158])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HKFda1ZuUt9o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "biased_prediction = transfer_model.predict(resized_test_images)\n",
        "biased_prediction[158]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cfskOX60Ut9q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  True label:\n",
        "y_test_encoded[158]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gWYKHSmQUt9x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  Scores: lower is better: smaller distance between prediction and true label.  \n",
        "#  Try looking at prediction scores before and after training, and after different amounts of training.\n",
        "#  Why (and when) might our pre-trained model do worse on these scores?\n",
        "\n",
        "#  Biased\n",
        "print(mean_squared_error(y_test_encoded[:1000],biased_prediction))\n",
        "mean_squared_log_error(y_test_encoded[:1000],biased_prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uVYcgQXgUt9y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  Unbiased\n",
        "print(mean_squared_error(y_test_encoded[:1000],unbiased_prediction))\n",
        "mean_squared_log_error(y_test_encoded[:1000],unbiased_prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6VQ5ov2oOG4d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}