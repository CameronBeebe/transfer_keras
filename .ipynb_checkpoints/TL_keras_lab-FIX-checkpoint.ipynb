{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Beebs/miniconda3/envs/keras/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, load_model, Model, Input\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPool2D, InputLayer, ZeroPadding2D, GlobalAvgPool2D, Reshape, Softmax\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data: (32,32,3) Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This tutorial attempts to achieve transfer learning on incompatible image sizes with MobileNet.\n",
    "#  Why do this, when we could just load a different (compatible) data set, or use a different model?\n",
    "#  Because!  Well, this is a tutorial, and it illustrates the practical issues of transfer learning.\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#  Check shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c2d982048>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Convince yourself that the labels are consistent with the data.  \n",
    "#See https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "print(y_train[7])   \n",
    "plt.imshow(x_train[4999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#  Resize.\n",
    "#  One option to deal with the fact that MobileNet does not like (32,32,3) shape is to resize the images.\n",
    "#  NOTE:  On my machine, resizing the entire training data set would take, according to my precise calculations, a very long time.\n",
    "#  I will only be resizing and training on 5,000 (about 50 minutes for me), creating a 2 gig file.\n",
    "#  You will have to do this on your own, but it is possible to store large files on github: https://git-lfs.github.com\n",
    "\n",
    "#  Base case.\n",
    "\n",
    "\n",
    "resized_train_data = []\n",
    "resized_train_data = np.reshape(np.append(resized_train_data, resize(x_train[0],(128,128,3))),(128,128,3))\n",
    "\n",
    "#  Change range to 50000 if you want to do the entire set.    \n",
    "#  NOTE:  It may take a while.  If you know a better way, please share. :)\n",
    "\n",
    "for row in range(5000):\n",
    "    if row > 0:\n",
    "        resized = resize(x_train[row],(128,128,3))\n",
    "        resized_train_data = np.reshape(np.append(resized_train_data, resized),((row+1),128,128,3))\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(resized_train_data[4999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resized_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data:  Binary Reps. of Categories, Unrolling, Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train_unrolled = x_train.reshape(-1,32*32*3) / 256\n",
    "\n",
    "#Reshape for convolutions\n",
    "x_train_reshape = x_train.reshape(-1,32,32,3) / 256\n",
    "print(x_train_reshape.shape)\n",
    "#print(x_train_unrolled.shape)\n",
    "y_train_encoded = np_utils.to_categorical(y_train)\n",
    "print(y_train_encoded.shape)\n",
    "\n",
    "x_test_unrolled = x_test.reshape(-1,32*32*3) / 256\n",
    "y_test_encoded = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_resized = np.load('resized_5k_images.npy')\n",
    "\n",
    "#  Or, alternately if you saved as .npz\n",
    "with np.load('/Users/Beebs/Desktop/resized_5k_images.npz') as data:\n",
    "    load_resized = data['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 128, 128, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onek_labels = y_test_encoded[:1000]\n",
    "onek_resized = load_resized[:1000,:,:]\n",
    "onek_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fivek_labels = y_test_encoded[:5000]\n",
    "#fivek_resized = load_resized[:5000,:,:]\n",
    "fivek_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Unbiased Conv. NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh = MobileNet(input_shape=(128,128,3),include_top =True, weights=None,classes=10)\n",
    "fresh.summary()\n",
    "len(fresh.layers)\n",
    "fresh.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fresh.fit(onek_resized,onek_labels,epochs = 5,batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Adapters for Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Documentation for MobileNet says smaller shapes allowed, but throws error.  https://keras.io/applications/#mobilenet\n",
    "#Thus, we have to adapt a new model to take the dimensions of our data.\n",
    "\n",
    "rand_init_model = Sequential()\n",
    "\n",
    "rand_init_model.add(InputLayer(input_shape=(128,128,3),name='INPUT'))\n",
    "#rand_init_model.add(ZeroPadding2D())\n",
    "#rand_init_model.add(Conv2D(filters=1,kernel_size=(1,1),input_shape=(32,32,3),name='CONVA'))\n",
    "#rand_init_model.add(Dense(64,input_dim=(32*32*3), activation = 'sigmoid',name='cifar10_in_adapter'))\n",
    "rand_init_model.layers.extend(fresh.layers[1:])\n",
    "\n",
    "#print(rand_init_model.layers[-1].output_shape)\n",
    "#rand_init_model.add(ZeroPadding2D())\n",
    "#print(rand_init_model.layers[-1].output_shape)\n",
    "#rand_init_model.add(Reshape((10)))\n",
    "#print(rand_init_model.layers[-1].output_shape)\n",
    "rand_init_model.add(GlobalAvgPool2D(data_format='channels_first'))\n",
    "#print(rand_init_model.layers[-1].output_shape)\n",
    "rand_init_model.add(Reshape((1,1,-1)))\n",
    "\n",
    "#print(rand_init_model.layers[-1].output_shape)\n",
    "#rand_init_model.add(Dropout(rate=0.001))\n",
    "#print(rand_init_model.layers[-1].output_shape)\n",
    "rand_init_model.add(Conv2D(filters=10,kernel_size=(5,5),name='CONVZ'))\n",
    "print(rand_init_model.layers[-1].output_shape)\n",
    "rand_init_model.add(Softmax())\n",
    "print(rand_init_model.layers[-1].output_shape)\n",
    "#rand_init_model.add(Dense(10,activation = 'softmax', name='cifar10_class_adapter'))\n",
    "rand_init_model.add(Reshape((-1,)))\n",
    "print(rand_init_model.layers[-1].output_shape)\n",
    "\n",
    "rand_init_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "rand_init_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history_fresh = rand_init_model.fit(x_train,y_train_encoded, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_fresh.history['loss'])\n",
    "#plt.plot(history_fresh.history['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Biased Conv. NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained weights only exist for certain shapes, which is why we get an error with smaller image sizes.\n",
    "# We will use the weights anyways for this tutorial, but try loading other data sets with compatible image sizes.\n",
    "trained_model = MobileNet(input_shape = (128,128,3),include_top = False, weights='imagenet')\n",
    "\n",
    "#Freeze: keep some pre-trained weights as they are.\n",
    "#Try freezing other layers.\n",
    "for layer in trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Check number of trainable parameters after freezing layers.\n",
    "trained_model.summary()\n",
    "#trained_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new model to add the trained model into.  Again with adapters.\n",
    "transfer_model = Sequential()\n",
    "#transfer_model.add(Dense(64,input_dim=(32*32*3), activation = 'sigmoid',name='cifar10_in_adapter'))\n",
    "    \n",
    "    \n",
    "#Extend list of layers to include layers of trained_model.\n",
    "#Check summary on model to see the layer structures.\n",
    "#Remember, include_top = False has already chopped off the classification layers.\n",
    "\n",
    "transfer_model.add(InputLayer(input_shape=(128,128,3),name='INPUT'))\n",
    "\n",
    "transfer_model.layers.extend(trained_model.layers[1:97])\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "#transfer_model.add(Reshape((1,1,-1)))\n",
    "#transfer_model.add(Reshape((-1,)))\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "#transfer_model.add(Conv2D(filters=10,kernel_size=(3,3),name='CONVZ'))\n",
    "transfer_model.add(GlobalAvgPool2D(data_format='channels_first'))\n",
    "transfer_model.add(Dropout(rate=0.001))\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "#transfer_model.add(Flatten())\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "transfer_model.add(Dense(10, activation = 'softmax', name = 'cifar10_class_adapter'))\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "#transfer_model.add(GlobalAvgPool2D(data_format='channels_first'))\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "#transfer_model.add(Reshape((1,1,-1)))\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "#transfer_model.add(Dropout(rate=0.001))\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "#transfer_model.add(Conv2D(filters=10,kernel_size=(3,3),name='CONVZ'))\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "#transfer_model.add(Softmax())\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "#transfer_model.add(Reshape((-1,)))\n",
    "\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "#transfer_model.add(Softmax())\n",
    "\n",
    "#transfer_model.add(Flatten())\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "\n",
    "#Experiment: freeze all trainable params.  What do you expect to happen to the acc?  Check summary.\n",
    "#transfer_model.trainable = False  \n",
    "transfer_model.summary()\n",
    "transfer_model.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "transfer_model.fit(fivek_resized,fivek_labels,epochs=10,batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = MobileNet(input_shape = (128,128,3),include_top = False, weights='imagenet')\n",
    "transfer_model = Sequential()\n",
    "transfer_model.layers.extend(trained_model.layers[1:])\n",
    "\n",
    "#Freeze: keep some pre-trained weights as they are.\n",
    "#Try freezing other layers.\n",
    "#for layer in trained_model.layers:\n",
    "#    layer.trainable = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 130, 130, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 64, 64, 32)        864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (Activation)      (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_1 (ZeroPadding2D)   (None, 66, 66, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 64, 64, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (Activation)  (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 64, 64, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (Activation)  (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 66, 66, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 32, 32, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (Activation)  (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 32, 32, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (Activation)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_3 (ZeroPadding2D)   (None, 34, 34, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 32, 32, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (Activation)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 32, 32, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (Activation)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 34, 34, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 16, 16, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (Activation)  (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 16, 16, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (Activation)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_5 (ZeroPadding2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 16, 16, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (Activation)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 16, 16, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (Activation)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 8, 8, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 8, 8, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_7 (ZeroPadding2D)   (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_8 (ZeroPadding2D)   (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_9 (ZeroPadding2D)   (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_10 (ZeroPadding2D)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_11 (ZeroPadding2D)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (Activation) (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 4, 4, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (Activation) (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_13 (ZeroPadding2D)  (None, 6, 6, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 4, 4, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (Activation) (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 4, 4, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (Activation) (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 1, 10)          10250     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1, 1, 10)          0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 3,239,114\n",
      "Trainable params: 10,250\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  Since we are doing a more complex model, we use the functional API Model() class from keras.\n",
    "#  We manually describe the inputs and outputs.\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "#trained_model = MobileNet(input_shape = (128,128,3),include_top = False, weights='imagenet')\n",
    "\n",
    "#Freeze: keep some pre-trained weights as they are.\n",
    "#Try freezing other layers.\n",
    "#for layer in trained_model.layers:\n",
    "#    layer.trainable = False\n",
    "\n",
    "    \n",
    "\n",
    "#tf.reset_default_graph()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with tf.variable_scope(name_or_scope=\"transferring\",reuse=None):\n",
    "    \n",
    "    inputs = Input(shape = (128,128,3)) \n",
    "\n",
    "        #transfer_model = Sequential()\n",
    "        #transfer_model = Sequential([Input(shape = (128,128,3))]) \n",
    "        #transfer_model.layers.extend(trained_model.layers[1:])\n",
    "\n",
    "\n",
    "\n",
    "    trained_model = MobileNet(input_shape = (128,128,3),include_top = False, weights='imagenet', input_tensor = inputs)\n",
    "\n",
    "    #Freeze: keep some pre-trained weights as they are.\n",
    "    #Try freezing other layers.\n",
    "    for layer in trained_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    #  We can just plug the biased model into a layer.\n",
    "    #x = trained_model(inputs)\n",
    "\n",
    "    #  Then, if we want we can copy as close as possible the \n",
    "    #  structure of the layers removed by include_top=False.\n",
    "\n",
    "    x = GlobalAvgPool2D(data_format='channels_last')(trained_model.output)\n",
    "    x = Reshape((1,1,-1))(x)\n",
    "    #x = Dropout(rate=0.001)(x)\n",
    "    x = Conv2D(filters=10,kernel_size=(1,1))(x)\n",
    "    x = Activation(activation = 'softmax')(x)\n",
    "    predictions = Reshape((-1,))(x)\n",
    "\n",
    "\n",
    "    transferable_model = Model(inputs = inputs,outputs = predictions)\n",
    "    transferable_model.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
    "    transferable_model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2124/5000 [===========>..................] - ETA: 1:31 - loss: 2.7294 - acc: 0.1210"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-15483a5712d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransferable_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_resized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfivek_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "transferable_model.fit(load_resized,fivek_labels,epochs=5,batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history_transfer = transfer_model.fit(x_train_unrolled,y_train_encoded,epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_transfer.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress scientific notation for easier comparison.\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "#Predict and look at an example to compare between biased and unbiased.\n",
    "unbiased_prediction = rand_init_model.predict_proba(x_test_unrolled)\n",
    "sum(unbiased_prediction[76])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biased_prediction = transfer_model.predict_proba(x_test_unrolled)\n",
    "biased_prediction[76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#True label:\n",
    "y_test_encoded[76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unbiased\n",
    "#Brier score, lower is better: smaller distance between prediction and true label.  \n",
    "#Try looking at prediction scores before and after training.\n",
    "unbiased_diff = y_test_encoded - unbiased_prediction\n",
    "score_u = np.sum((1/10000)*(np.power(unbiased_diff,2)),axis=1)\n",
    "\n",
    "#Overall score for 10000 test examples.\n",
    "sum(score_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Biased\n",
    "biased_diff = y_test_encoded - biased_prediction  \n",
    "score_b = np.sum((1/10000)*(np.power(biased_diff,2)),axis=1)\n",
    "\n",
    "sum(score_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = fresh.layers[2]\n",
    "b = a.get_weights()\n",
    "b[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    VarSc\n",
    "    hk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
