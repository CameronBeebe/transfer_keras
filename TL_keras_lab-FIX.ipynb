{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "#import tensorflow\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPool2D, InputLayer, ZeroPadding2D, GlobalAvgPool2D, Reshape, Softmax\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data: (32,32,3) Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convince yourself that the labels are consistent with the data.  \n",
    "#See https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "print(y_train[7])   \n",
    "plt.imshow(x_train[4999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#  Resize.\n",
    "#  One option to deal with the fact that MobileNet does not like (32,32,3) shape is to resize the images.\n",
    "#  NOTE:  On my machine, resizing the entire training data set would take, according to my precise calculations, a very long time.\n",
    "#  I will only be resizing and training on 5,000 (about 50 minutes for me).\n",
    "\n",
    "#  Base case.\n",
    "\n",
    "\n",
    "resized_train_data = []\n",
    "resized_train_data = np.reshape(np.append(resized_train_data, resize(x_train[0],(128,128,3))),(128,128,3))\n",
    "\n",
    "#  Change range to 50000 if you want to do the entire set.    \n",
    "#  NOTE:  It may take a while.  If you know a better way, please share. :)\n",
    "\n",
    "\n",
    "for row in range(5000):\n",
    "    if row > 0:\n",
    "        resized = resize(x_train[row],(128,128,3))\n",
    "        resized_train_data = np.reshape(np.append(resized_train_data, resized),((row+1),128,128,3))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(resized_train_data[4999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Sloppy data (just reading off the timer), but resizing scales horribly.\n",
    "seconds = np.array([23,84,211,436])\n",
    "drange = np.array([500,1000,1500,2000])\n",
    "plt.plot(drange,seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data:  Binary Reps. of Categories, Unrolling, Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_unrolled = x_train.reshape(-1,32*32*3) / 256\n",
    "\n",
    "#Reshape for convolutions\n",
    "x_train_reshape = x_train.reshape(-1,32,32,3) / 256\n",
    "print(x_train_reshape.shape)\n",
    "#print(x_train_unrolled.shape)\n",
    "y_train_encoded = np_utils.to_categorical(y_train)\n",
    "print(y_train_encoded.shape)\n",
    "\n",
    "x_test_unrolled = x_test.reshape(-1,32*32*3) / 256\n",
    "y_test_encoded = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_resized = np.load('resized_5k_images.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onek_labels = y_test_encoded[:1000]\n",
    "onek_resized = load_resized[:1000,:,:]\n",
    "onek_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fivek_labels = y_test_encoded[:5000]\n",
    "fivek_resized = load_resized[:5000,:,:]\n",
    "fivek_resized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Unbiased Conv. NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh = MobileNet(input_shape=(128,128,3),include_top =True, weights=None,classes=10)\n",
    "fresh.summary()\n",
    "len(fresh.layers)\n",
    "fresh.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fresh.fit(onek_resized,onek_labels,epochs = 5,batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Adapters for Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Documentation for MobileNet says smaller shapes allowed, but throws error.  https://keras.io/applications/#mobilenet\n",
    "#Thus, we have to adapt a new model to take the dimensions of our data.\n",
    "\n",
    "rand_init_model = Sequential()\n",
    "\n",
    "rand_init_model.add(InputLayer(input_shape=(128,128,3),name='INPUT'))\n",
    "#rand_init_model.add(ZeroPadding2D())\n",
    "#rand_init_model.add(Conv2D(filters=1,kernel_size=(1,1),input_shape=(32,32,3),name='CONVA'))\n",
    "#rand_init_model.add(Dense(64,input_dim=(32*32*3), activation = 'sigmoid',name='cifar10_in_adapter'))\n",
    "rand_init_model.layers.extend(fresh.layers[1:])\n",
    "\n",
    "#print(rand_init_model.layers[-1].output_shape)\n",
    "#rand_init_model.add(ZeroPadding2D())\n",
    "#print(rand_init_model.layers[-1].output_shape)\n",
    "#rand_init_model.add(Reshape((10)))\n",
    "#print(rand_init_model.layers[-1].output_shape)\n",
    "rand_init_model.add(GlobalAvgPool2D(data_format='channels_first'))\n",
    "#print(rand_init_model.layers[-1].output_shape)\n",
    "rand_init_model.add(Reshape((1,1,-1)))\n",
    "\n",
    "#print(rand_init_model.layers[-1].output_shape)\n",
    "#rand_init_model.add(Dropout(rate=0.001))\n",
    "#print(rand_init_model.layers[-1].output_shape)\n",
    "rand_init_model.add(Conv2D(filters=10,kernel_size=(5,5),name='CONVZ'))\n",
    "print(rand_init_model.layers[-1].output_shape)\n",
    "rand_init_model.add(Softmax())\n",
    "print(rand_init_model.layers[-1].output_shape)\n",
    "#rand_init_model.add(Dense(10,activation = 'softmax', name='cifar10_class_adapter'))\n",
    "rand_init_model.add(Reshape((-1,)))\n",
    "print(rand_init_model.layers[-1].output_shape)\n",
    "\n",
    "rand_init_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "rand_init_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history_fresh = rand_init_model.fit(x_train,y_train_encoded, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_fresh.history['loss'])\n",
    "#plt.plot(history_fresh.history['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Biased Conv. NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained weights only exist for certain shapes, which is why we get an error with smaller image sizes.\n",
    "# We will use the weights anyways for this tutorial, but try loading other data sets with compatible image sizes.\n",
    "trained_model = MobileNet(input_shape = (128,128,3),include_top = False, weights='imagenet')\n",
    "\n",
    "#Freeze: keep some pre-trained weights as they are.\n",
    "#Try freezing other layers.\n",
    "for layer in trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Check number of trainable parameters after freezing layers.\n",
    "trained_model.summary()\n",
    "#trained_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new model to add the trained model into.  Again with adapters.\n",
    "transfer_model = Sequential()\n",
    "#transfer_model.add(Dense(64,input_dim=(32*32*3), activation = 'sigmoid',name='cifar10_in_adapter'))\n",
    "    \n",
    "    \n",
    "#Extend list of layers to include layers of trained_model.\n",
    "#Check summary on model to see the layer structures.\n",
    "#Remember, include_top = False has already chopped off the classification layers.\n",
    "\n",
    "transfer_model.add(InputLayer(input_shape=(128,128,3),name='INPUT'))\n",
    "\n",
    "transfer_model.layers.extend(trained_model.layers[1:97])\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "#transfer_model.add(Reshape((1,1,-1)))\n",
    "#transfer_model.add(Reshape((-1,)))\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "#transfer_model.add(Conv2D(filters=10,kernel_size=(3,3),name='CONVZ'))\n",
    "transfer_model.add(GlobalAvgPool2D(data_format='channels_first'))\n",
    "transfer_model.add(Dropout(rate=0.001))\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "#transfer_model.add(Flatten())\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "transfer_model.add(Dense(10, activation = 'softmax', name = 'cifar10_class_adapter'))\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "#transfer_model.add(GlobalAvgPool2D(data_format='channels_first'))\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "#transfer_model.add(Reshape((1,1,-1)))\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "#transfer_model.add(Dropout(rate=0.001))\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "#transfer_model.add(Conv2D(filters=10,kernel_size=(3,3),name='CONVZ'))\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "#transfer_model.add(Softmax())\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "#transfer_model.add(Reshape((-1,)))\n",
    "\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "#transfer_model.add(Softmax())\n",
    "\n",
    "transfer_model.add(Flatten())\n",
    "print(transfer_model.layers[-1].output_shape)\n",
    "\n",
    "#Experiment: freeze all trainable params.  What do you expect to happen to the acc?  Check summary.\n",
    "#transfer_model.trainable = False  \n",
    "transfer_model.summary()\n",
    "transfer_model.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "transfer_model.fit(fivek_resized,fivek_labels,epochs=10,batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history_transfer = transfer_model.fit(x_train_unrolled,y_train_encoded,epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_transfer.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress scientific notation for easier comparison.\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "#Predict and look at an example to compare between biased and unbiased.\n",
    "unbiased_prediction = rand_init_model.predict_proba(x_test_unrolled)\n",
    "sum(unbiased_prediction[76])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biased_prediction = transfer_model.predict_proba(x_test_unrolled)\n",
    "biased_prediction[76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#True label:\n",
    "y_test_encoded[76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unbiased\n",
    "#Brier score, lower is better: smaller distance between prediction and true label.  \n",
    "#Try looking at prediction scores before and after training.\n",
    "unbiased_diff = y_test_encoded - unbiased_prediction\n",
    "score_u = np.sum((1/10000)*(np.power(unbiased_diff,2)),axis=1)\n",
    "\n",
    "#Overall score for 10000 test examples.\n",
    "sum(score_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Biased\n",
    "biased_diff = y_test_encoded - biased_prediction  \n",
    "score_b = np.sum((1/10000)*(np.power(biased_diff,2)),axis=1)\n",
    "\n",
    "sum(score_b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
